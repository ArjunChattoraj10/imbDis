1- logLik(lr1)/logLik(null_lr)
# ensure presence of file dependencies
source("train_test.R")
# Ensure presence of file dependencies
source("train_test.R")
getwd()
sim_dat = read.csv("../data/simulated_data_arjun.csv")
# decision tree with all predictors
dec_tree = train(y ~ ., data = train_dat, method = "rpart")
library(caret)
library(rattle)
library(rpart)
# decision tree with all predictors
dec_tree = train(y ~ ., data = train_dat, method = "rpart")
# Ensure presence of file dependencies
source("train_test.R") # Performs the train/test split
# Ensure presence of file dependencies
source("train_test.R") # Performs the train/test split
# Ensure presence of file dependencies
source("train_test.R") # Performs the train/test split
# Ensure presence of file dependencies
source("train_test.R") # Performs the train/test split
source("class_def.R")  # Loads the class into the environment
library(caret)
library(rattle)
library(rpart)
# decision tree with all predictors
dec_tree = train(y ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree$finalModel, palettes = c("Reds","Greens"))
# decision tree with all predictors
dec_tree = train(factor(y) ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree$finalModel, palettes = c("Reds","Greens"))
# decision tree with all predictors
dec_tree = train(y ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree$finalModel, palettes = c("Reds","Greens"))
# decision tree with all predictors
dec_tree = train(factor(y) ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree$finalModel, palettes = c("Reds","Greens"))
prune.control = rpart.control(xval = 10)
dec2 = rpart(y ~ ., data = train_dat, method = "class", control = prune.control)
fancyRpartPlot(dec2, palettes = c("Reds","Greens"))
# decision tree with all predictors
dec_tree_all = train(factor(y) ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_all$finalModel, palettes = c("Reds","Greens"))
# decision tree with 7 predictors
dec_tree_7 = train(factor(y) ~ x1+x2+x3+x4+x5+x6+x7, data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_7$finalModel, palettes = c("Reds","Greens"))
# decision tree with all predictors
dec_tree_all = train(factor(y) ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_all$finalModel, palettes = c("Reds","Greens"))
# decision tree with 7 predictors
dec_tree_7 = train(factor(y) ~ x1+x2+x3+x4+x5+x6+x7, data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_7$finalModel, palettes = c("Reds","Greens"))
# obtain predicted probabilities and labels
predict(dec_tree_all$finalModel, test_dat)
train_dat
head(train_dat)
head(predict(dec_tree_all$finalModel, test_dat))
# obtain predicted probabilities and labels
predict(dec_tree_all$finalModel, test_dat)
predict(dec_tree_7$finalModel, test_dat)
# obtain predicted probabilities and labels
predict(dec_tree_all$finalModel, test_dat)
predict(dec_tree_7$finalModel, test_dat)
# obtain predicted probabilities and labels
preds_DT_all = predict(dec_tree_all$finalModel, test_dat)
preds_DT_7 = predict(dec_tree_7$finalModel, test_dat)
preds_DT_7
predict(dec_tree_7$finalModel, test_dat)
head(preds_DT_7)
head(test_dat)
# decision tree with all predictors
dec_tree_all = train(factor(y, levels = c(1,0)) ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_all$finalModel, palettes = c("Reds","Greens"))
# obtain predicted probabilities and labels
preds_DT_all = predict(dec_tree_all$finalModel, test_dat)
head(preds_DT_all)
# decision tree with all predictors
dec_tree_all = train(factor(y) ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_all$finalModel, palettes = c("Reds","Greens"))
# decision tree with 7 predictors
dec_tree_7 = train(factor(y) ~ x1+x2+x3+x4+x5+x6+x7, data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_7$finalModel, palettes = c("Reds","Greens"))
# obtain predicted probabilities and labels
preds_DT_all = predict(dec_tree_all$finalModel, test_dat)
preds_DT_7 = predict(dec_tree_7$finalModel, test_dat)
preds_DT_all > 0.7, 1, 0
ifelse(preds_DT_all > 0.7, 1, 0)
preds_DT_all[,1]
preds_DT_all = predict(dec_tree_all$finalModel, test_dat)
labs_DT_all = ifelse(preds_DT_all[,1] > 0.5, 0, 1)
preds_DT_7 = predict(dec_tree_7$finalModel, test_dat)
labs_DT_7 = ifelse(preds_DT_7[,1] > 0.5, 0, 1)
# Define class - DT all predictors
SM_DT_all = simMetric(test_dat, labs_DT_all, preds_DT_all, 1)
# Define class - DT all predictors
SM_DT_all = simMetric(test_dat$y, labs_DT_all, preds_DT_all, 1)
labs_DT_all
preds_DT_all[,2]
# Define class - DT all predictors
SM_DT_all = simMetric(test_dat$y, labs_DT_all, preds_DT_all[,2], 1)
preds_DT_all[,2]
labs_DT_all
test_dat$y
labs_DT_all
# Define class - DT all predictors
SM_DT_all = simMetric(test_dat$y, labs_DT_all, preds_DT_all[,2], 1)
source("class_def.R")  # Loads the class into the environment
# Define class - DT all predictors
SM_DT_all = simMetric(test_dat$y, labs_DT_all, preds_DT_all[,2], 1)
auc.simMetric(SM_DT_all)
f1.simMetric(SM_DT_all)
auc.simMetric(SM_DT_all)
f1.simMetric(SM_DT_all)
SM_DT_7 = simMetric(test_dat$y, labs_DT_7, preds_DT_7[,2], 1)
SM_DT_7 = simMetric(test_dat$y, labs_DT_7, preds_DT_7[,2], 1)
# c-statistic and F1 for 7 preds DT
auc.simMetric(SM_DT_7)
f1.simMetric(SM_DT_7)
tc = trainControl(method = "cv", number = 10)
rf = train(y ~ ., data = train_dat, method = "rf",
trControl = trainControl(method = "cv"))
rf$preds
# tc = trainControl(method = "cv", number = 10)
rf = train(y ~ ., data = train_dat, method = "rf")
# Ensure presence of file dependencies
source("train_test.R") # Performs the train/test split
source("class_def.R")  # Loads the class into the environment
library(caret)
library(rattle)
library(rpart)
# decision tree with 7 predictors
dec_tree_7 = train(factor(y) ~ x1+x2+x3+x4+x5+x6+x7, data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_7$finalModel, palettes = c("Reds","Greens"))
# decision tree with all predictors
dec_tree_all = train(factor(y) ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_all$finalModel, palettes = c("Reds","Greens"))
# obtain predicted probabilities and labels - 7 preds
# col 1 is for label 0, col 2 is for label 1
preds_DT_7 = predict(dec_tree_7$finalModel, test_dat)[,2]
labs_DT_7 = ifelse(preds_DT_7 > 0.5, 1, 0)
# obtain predicted probabilities and labels - all preds
preds_DT_all = predict(dec_tree_all$finalModel, test_dat)[,2]
labs_DT_all = ifelse(preds_DT_all > 0.5, 1, 0)
# Define classes
SM_DT_7 = simMetric(test_dat$y, labs_DT_7, preds_DT_7, 1)
SM_DT_all = simMetric(test_dat$y, labs_DT_all, preds_DT_all, 1)
# c-statistic and F1 for 7 preds DT
auc.simMetric(SM_DT_7)
f1.simMetric(SM_DT_7)
# c-statistic and F1 for all preds DT
auc.simMetric(SM_DT_all)
f1.simMetric(SM_DT_all)
# save the files to csv
data.frame(preds_DT_7, labs_DT_7, preds_DT_all, labs_DT_all)
# save the files to csv
data.frame(test_dat$y, preds_DT_7, labs_DT_7, preds_DT_all, labs_DT_all)
# save the files to csv
res_DT = data.frame(test_dat$y, preds_DT_7, labs_DT_7, preds_DT_all, labs_DT_all)
head(res_DT)
names(res_DT)
names(res_DT)[1] = "orig"
names(res_DT)[1] = "orig"
names(res_DT)
write.csv(res_DT, "res_DT.csv")
write.csv(res_DT, "../data/res_DT.csv")
tc = trainControl(method = "cv", number = 10)
RF_7 = train(factor(y) ~ x1+x2+x3+x4+x5+x6+x7, data = train_dat, method = "rf", trControl = tc)
# random forest with all predictors
RF_all = train(factor(y) ~ ., data = train_dat, method = "rf", trControl = tc)
# obtain predicted probabilities and labels - 7 preds
preds_RF_7 = predict(RF_7$finalModel, test_dat, type = "prob")[,2]
labs_RF_7 = predict(RF_7$finalModel, test_dat) # random forest voting labels
# obtain predicted probabilities and labels - all preds
preds_RF_all = predict(RF_all$finalModel, test_dat, type = "prob")[,2]
labs_RF_all = predict(RF_all$finalModel, test_dat) # random forest voting labels
# save the files to csv
res_RF = data.frame(test_dat$y, preds_DT_7, labs_DT_7, preds_DT_all, labs_DT_all)
names(res_RF)[1] = "orig"
head(res_RF)
write.csv(res_RF, "../data/res_RF.csv", row.names = FALSE)
write.csv(res_DT, "../data/res_DT.csv", row.names = FALSE)
# save the files to csv
res_DT = data.frame(test_dat$y, preds_DT_7, labs_DT_7, preds_DT_all, labs_DT_all)
names(res_DT)[1] = "orig"
write.csv(res_DT, "../data/res_DT.csv", row.names = FALSE)
write.csv(res_DT, "../data/res_DT.csv", append = F, row.names = FALSE)
write.csv(res_DT, "../data/res_DT.csv", row.names = FALSE)
write.csv(res_RF, "../data/res_RF.csv", row.names = FALSE)
# save the files to csv
res_RF = data.frame(test_dat$y, preds_RF_7, labs_RF_7, preds_RF_all, labs_RF_all)
names(res_RF)[1] = "orig"
head(res_RF)
res_RF = data.frame(test_dat$y, preds_RF_7, labs_RF_7, preds_RF_all, labs_RF_all)
names(res_RF)[1] = "orig"
write.csv(res_RF, "../data/res_RF.csv", row.names = FALSE)
res_DT = data.frame(test_dat$y, preds_DT_7, labs_DT_7, preds_DT_all, labs_DT_all)
names(res_DT)[1] = "orig"
write.csv(res_DT, "../data/res_DT.csv", row.names = FALSE)
# save the files to csv
res_LR = data.frame(test_dat$y, preds_LR_7, labs_LR_7, preds_LR_lin, labs_LR_lin,
preds_LR_full, labs_LR_full)
# logistic regression with 7 predictors - linear
LR_7 = glm(y ~ x1+x2+x3+x4+x5+x6+x7, data = train_dat, family = "binomial")
# logistic regression with all predictors - linear
LR_lin = glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = train_dat, family = "binomial")
# logistic regression with all predictors - full complexity
LR_full = glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x7:x8+x9+I(x9^2)+x10+I(x10^2)+I(x10^3),
data = train_dat, family = "binomial")
# Aside
# calculate McFadden's R-squared
# details: https://thestatsgeek.com/2014/02/08/r-squared-in-logistic-regression/
null_lr = glm(y ~ 1, train_dat, family = binomial)
1 - logLik(LR_7)/logLik(null_lr)
1 - logLik(LR_lin)/logLik(null_lr)
1 - logLik(LR_full)/logLik(null_lr)
# obtain predicted probabilities and labels - 7 preds
preds_LR_7 = predict(LR_7, test_dat, type = "response")
labs_LR_7 = ifelse(preds_LR_7 > 0.5, 1, 0)
# obtain predicted probabilities and labels - all preds linear
preds_LR_lin = predict(LR_lin, test_dat, type = "response")
labs_LR_lin = ifelse(preds_LR_lin > 0.5, 1, 0)
# obtain predicted probabilities and labels - all preds full
preds_LR_full = predict(LR_full, test_dat, type = "response")
labs_LR_full = ifelse(preds_LR_full > 0.5, 1, 0)
# save the files to csv
res_LR = data.frame(test_dat$y, preds_LR_7, labs_LR_7, preds_LR_lin, labs_LR_lin,
preds_LR_full, labs_LR_full)
names(res_LR)[1] = "orig"
write.csv(res_LR, "../data/res_LR.csv", row.names = FALSE)
# c-statistic and F1 for 7 preds DT
auc.simMetric(SM_DT_7)
f1.simMetric(SM_DT_7)
# c-statistic and F1 for all preds DT
auc.simMetric(SM_DT_all)
f1.simMetric(SM_DT_all)
# c-statistic and F1 for 7 preds RF
auc.simMetric(SM_RF_7)
# Define classes
SM_RF_7 = simMetric(test_dat$y, labs_RF_7, preds_RF_7, 1)
SM_RF_all = simMetric(test_dat$y, labs_RF_all, preds_RF_all, 1)
# c-statistic and F1 for 7 preds RF
auc.simMetric(SM_RF_7)
f1.simMetric(SM_RF_7)
auc.simMetric(SM_DT_7)
f1.simMetric(SM_DT_7)
auc.simMetric(SM_DT_7)
auc.simMetric(SM_DT_all)
# c-statistic and F1 for 7 preds RF
auc.simMetric(SM_RF_7)
# c-statistic and F1 for all preds RF
auc.simMetric(SM_RF_all)
1 - logLik(LR_7)/logLik(null_lr)
1 - logLik(LR_lin)/logLik(null_lr)
1 - logLik(LR_full)/logLik(null_lr)
# obtain predicted probabilities and labels - 7 preds
preds_LR_7 = predict(LR_7, test_dat, type = "response")
labs_LR_7 = ifelse(preds_LR_7 > 0.5, 1, 0)
# obtain predicted probabilities and labels - all preds linear
preds_LR_lin = predict(LR_lin, test_dat, type = "response")
labs_LR_lin = ifelse(preds_LR_lin > 0.5, 1, 0)
# obtain predicted probabilities and labels - all preds full
preds_LR_full = predict(LR_full, test_dat, type = "response")
labs_LR_full = ifelse(preds_LR_full > 0.5, 1, 0)
# Define classes
SM_LR_7 = simMetric(test_dat$y, labs_LR_7, preds_LR_7, 1)
SM_LR_lin = simMetric(test_dat$y, labs_LR_lin, preds_LR_lin, 1)
SM_LR_full = simMetric(test_dat$y, labs_LR_full, preds_LR_full, 1)
# c-statistic and F1 for 7 preds LR
auc.simMetric(SM_LR_7)
f1.simMetric(SM_LR_7)
# c-statistic and F1 for all preds linear LR
auc.simMetric(SM_LR_lin)
f1.simMetric(SM_LR_lin)
# c-statistic and F1 for all preds full LR
auc.simMetric(SM_LR_full)
f1.simMetric(SM_LR_full)
auc.simMetric(SM_LR_7)
auc.simMetric(SM_LR_lin)
auc.simMetric(SM_LR_full)
probs = runif(10)
probs
labs = rbinom(10,1,0.5)
labs
mean((probs - labs)^2)
(probs - labs)^2
# Ensure presence of file dependencies
source("train_test.R") # Performs the train/test split
source("class_def.R")  # Loads the class into the environment
library(caret)
library(rattle)
library(rpart)
source("class_def.R")  # Loads the class into the environment
library(caret)
# Ensure presence of file dependencies
source("train_test.R") # Performs the train/test split
source("class_def.R")  # Loads the class into the environment
library(caret)
library(rattle)
library(rpart)
# decision tree with 7 predictors
dec_tree_7 = train(factor(y) ~ x1+x2+x3+x4+x5+x6+x7, data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_7$finalModel, palettes = c("Reds","Greens"))
# decision tree with all predictors
dec_tree_all = train(factor(y) ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_all$finalModel, palettes = c("Reds","Greens"))
# obtain predicted probabilities and labels - 7 preds
# col 1 is for label 0, col 2 is for label 1
preds_DT_7 = predict(dec_tree_7$finalModel, test_dat)[,2]
labs_DT_7 = ifelse(preds_DT_7 > 0.5, 1, 0)
# obtain predicted probabilities and labels - all preds
preds_DT_all = predict(dec_tree_all$finalModel, test_dat)[,2]
labs_DT_all = ifelse(preds_DT_all > 0.5, 1, 0)
# save the files to csv
res_DT = data.frame(test_dat$y, preds_DT_7, labs_DT_7, preds_DT_all, labs_DT_all)
names(res_DT)[1] = "orig"
write.csv(res_DT, "../data/res_DT.csv", row.names = FALSE)
# Define classes
SM_DT_7 = simMetric(test_dat$y, labs_DT_7, preds_DT_7, 1)
# Define classes
SM_DT_7 = simMetric(test_dat$y, preds_DT_7, 1)
SM_DT_all = simMetric(test_dat$y, preds_DT_all, 1)
# c-statistic and F1 for 7 preds DT
auc.simMetric(SM_DT_7)
f1.simMetric(SM_DT_7)
# c-statistic and F1 for 7 preds DT
auc.simMetric(SM_DT_7)
brier.simMetric(SM_DT_7)
# c-statistic and F1 for all preds DT
auc.simMetric(SM_DT_all)
brier.simMetric(SM_DT_all)
brier.simMetric(SM_DT_all)
# c-statistic and F1 for all preds DT
auc.simMetric(SM_DT_all)
# Define classes
SM_DT_7 = simMetric(test_dat$y, preds_DT_7, 1)
SM_DT_all = simMetric(test_dat$y, preds_DT_all, 1)
# c-statistic and F1 for 7 preds DT
auc.simMetric(SM_DT_7)
brier.simMetric(SM_DT_7)
source("class_def.R")  # Loads the class into the environment
brier.simMetric(SM_DT_7)
# c-statistic and F1 for 7 preds DT
auc.simMetric(SM_DT_7)
brier.simMetric(SM_DT_7)
# Ensure presence of file dependencies
source("train_test.R") # Performs the train/test split
source("class_def.R")  # Loads the class into the environment
library(caret)
library(rattle)
library(rpart)
# decision tree with 7 predictors
dec_tree_7 = train(factor(y) ~ x1+x2+x3+x4+x5+x6+x7, data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_7$finalModel, palettes = c("Reds","Greens"))
# decision tree with all predictors
dec_tree_all = train(factor(y) ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_all$finalModel, palettes = c("Reds","Greens"))
# obtain predicted probabilities and labels - 7 preds
# col 1 is for label 0, col 2 is for label 1
preds_DT_7 = predict(dec_tree_7$finalModel, test_dat)[,2]
labs_DT_7 = ifelse(preds_DT_7 > 0.5, 1, 0)
# obtain predicted probabilities and labels - all preds
preds_DT_all = predict(dec_tree_all$finalModel, test_dat)[,2]
labs_DT_all = ifelse(preds_DT_all > 0.5, 1, 0)
# save the files to csv
res_DT = data.frame(test_dat$y, preds_DT_7, labs_DT_7, preds_DT_all, labs_DT_all)
names(res_DT)[1] = "orig"
write.csv(res_DT, "../data/res_DT.csv", row.names = FALSE)
# Define classes
SM_DT_7 = simMetric(test_dat$y, preds_DT_7, 1)
SM_DT_all = simMetric(test_dat$y, preds_DT_all, 1)
# c-statistic and F1 for 7 preds DT
auc.simMetric(SM_DT_7)
brier.simMetric(SM_DT_7)
# Ensure presence of file dependencies
source("train_test.R") # Performs the train/test split
source("class_def.R")  # Loads the class into the environment
library(caret)
library(rattle)
library(rpart)
# decision tree with 7 predictors
dec_tree_7 = train(factor(y) ~ x1+x2+x3+x4+x5+x6+x7, data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_7$finalModel, palettes = c("Reds","Greens"))
# decision tree with all predictors
dec_tree_all = train(factor(y) ~ ., data = train_dat, method = "rpart")
fancyRpartPlot(dec_tree_all$finalModel, palettes = c("Reds","Greens"))
# obtain predicted probabilities and labels - 7 preds
# col 1 is for label 0, col 2 is for label 1
preds_DT_7 = predict(dec_tree_7$finalModel, test_dat)[,2]
labs_DT_7 = ifelse(preds_DT_7 > 0.5, 1, 0)
# obtain predicted probabilities and labels - all preds
preds_DT_all = predict(dec_tree_all$finalModel, test_dat)[,2]
labs_DT_all = ifelse(preds_DT_all > 0.5, 1, 0)
# save the files to csv
res_DT = data.frame(test_dat$y, preds_DT_7, labs_DT_7, preds_DT_all, labs_DT_all)
names(res_DT)[1] = "orig"
write.csv(res_DT, "../data/res_DT.csv", row.names = FALSE)
# Define classes
SM_DT_7 = simMetric(test_dat$y, preds_DT_7, 1)
SM_DT_all = simMetric(test_dat$y, preds_DT_all, 1)
# c-statistic and F1 for 7 preds DT
auc.simMetric(SM_DT_7)
brier.simMetric(SM_DT_7)
# c-statistic and F1 for all preds DT
auc.simMetric(SM_DT_all)
brier.simMetric(SM_DT_all)
test_dat$y
preds_DT_7
data.frame(test_dat$y, preds_DT_7)
brier.simMetric(SM_DT_7)
# c-statistic and F1 for all preds DT
auc.simMetric(SM_DT_all)
brier.simMetric(SM_DT_all)
source("train_test.R")
source("class_def.R")
library(caret)
set.seed(225)
# random forest with 7 predictors
tc = trainControl(method = "cv", number = 10)
RF_7 = train(factor(y) ~ x1+x2+x3+x4+x5+x6+x7, data = train_dat, method = "rf", trControl = tc)
# random forest with all predictors
RF_all = train(factor(y) ~ ., data = train_dat, method = "rf", trControl = tc)
# obtain predicted probabilities and labels - 7 preds
preds_RF_7 = predict(RF_7$finalModel, test_dat, type = "prob")[,2]
# obtain predicted probabilities and labels - all preds
preds_RF_all = predict(RF_all$finalModel, test_dat, type = "prob")[,2]
# save the files to csv
res_RF = data.frame(test_dat$y, preds_RF_7, preds_RF_all)
names(res_RF)[1] = "orig"
write.csv(res_RF, "../data/res_RF.csv", row.names = FALSE)
# Define classes
SM_RF_7 = simMetric(test_dat$y, preds_RF_7, 1)
SM_RF_all = simMetric(test_dat$y, preds_RF_all, 1)
# c-statistic and F1 for 7 preds RF
auc.simMetric(SM_RF_7)
brier.simMetric(SM_RF_7)
# c-statistic and F1 for all preds RF
auc.simMetric(SM_RF_all)
brier.simMetric(SM_RF_all)
source("class_def.R")
## to ensure call works
SM1 = simMetric(c(1,1,1,0), c(0.1,0.2,0.3,0.4), 1, c(0.1,0.2,0.3,0.4))
SM2 = simMetric(orig.labels = c(1,1,1,0), pred.probs = c(0.1,0.2,0.3,0.4), case = 1)
SM2 = simMetric(orig.labels = c(1,1,1,0), pred.probs = c(0.1,0.2,0.3,0.4), case = 1)
View(SM1)
SM2 = simMetric(labels = c(1,1,1,0), probs = c(0.1,0.2,0.3,0.4), case = 1)
set.seed(34)
n = 1000
orig.labels = rbinom(n, 1, 0.2)
pred.labels = rbinom(n, 1, 0.2)
# make realistic pred.probs
pred.probs= rep(0, n)
for(i in 1:n){
pred.probs[i] = ifelse(pred.labels[i] == 1,
rnorm(1,0.75, 0.2),
rnorm(1,0.25, 0.2))
}
pred.probs[pred.probs < 0] = 0.05
pred.probs[pred.probs > 1] = 0.95
case = 1
SM3 = simMetric(orig.labels, pred.probs, case)
SM3$auc = auc(SM3)
SM3$brier = f1(SM3)
SM3$brier = brier(SM3)
SM3$brier
SM3$auc
bins = seq(0.05,0.2,0.05)
SM4 = simMetric(orig.labels, pred.probs, case, bins)
SM4$auc = auc(SM4)
SM4$brier = brier(SM4)
source("class_def.R")
set.seed(34)
n = 1000
orig.labels = rbinom(n, 1, 0.2)
pred.labels = rbinom(n, 1, 0.2)
# make realistic pred.probs
pred.probs= rep(0, n)
for(i in 1:n){
pred.probs[i] = ifelse(pred.labels[i] == 1,
rnorm(1,0.75, 0.2),
rnorm(1,0.25, 0.2))
}
pred.probs[pred.probs < 0] = 0.05
pred.probs[pred.probs > 1] = 0.95
case = 1
SM3 = simMetric(orig.labels, pred.probs, case)
SM3$auc = auc(SM3)
SM3$brier = brier(SM3)
getwd()
source("class_def.R")
## to ensure call works
imbD1 = imbDis(c(1,1,1,0), c(0.1,0.2,0.3,0.4), 1, c(0.1,0.2,0.3,0.4))
imbD2 = imbDis(labels = c(1,1,1,0), pred = c(0.1,0.2,0.3,0.4), case = 1)
set.seed(34)
n = 1000
orig.labels = rbinom(n, 1, 0.2)
pred.labels = rbinom(n, 1, 0.2)
# make realistic pred.probs
pred.probs= rep(0, n)
for(i in 1:n){
pred.probs[i] = ifelse(pred.labels[i] == 1,
rnorm(1,0.75, 0.2),
rnorm(1,0.25, 0.2))
}
pred.probs[pred.probs < 0] = 0.05
pred.probs[pred.probs > 1] = 0.95
case = 1
imbD3 = imbDis(orig.labels, pred.probs, case)
imbD3$auc = auc(imbD3)
imbD3$brier = brier(imbD3)
imbD3$logLoss = logLoss(imbD3)
library(imbDis)
